looking:RSGroupInfoManagerImpl.flushConfig
RSGroupInfoManagerImpl	flushConfig
-----------------------
private synchronized void flushConfig(Map<String, RSGroupInfo> newGroupMap) throws IOException {
    // For offline mode persistence is still unavailable
    // We're refreshing in-memory state but only for servers in default group
    if (!isOnline()) {
        if (newGroupMap == holder.groupName2Group) {
            // When newGroupMap is this.rsGroupMap itself,
            // do not need to check default group and other groups as followed
            return;
        }
        LOG.debug("Offline mode, cannot persist to {}", RSGROUP_TABLE_NAME);
        Map<String, RSGroupInfo> oldGroupMap = Maps.newHashMap(holder.groupName2Group);
        RSGroupInfo oldDefaultGroup = oldGroupMap.remove(RSGroupInfo.DEFAULT_GROUP);
        RSGroupInfo newDefaultGroup = newGroupMap.remove(RSGroupInfo.DEFAULT_GROUP);
        if (!oldGroupMap.equals(newGroupMap) || /* compare both tables and servers in other groups */
        !oldDefaultGroup.getTables().equals(newDefaultGroup.getTables())) /* compare tables in default group */
        {
            throw new IOException("Only servers in default group can be updated during offline mode");
        }
        // Restore newGroupMap by putting its default group back
        newGroupMap.put(RSGroupInfo.DEFAULT_GROUP, newDefaultGroup);
        // Refresh rsGroupMap
        // according to the inputted newGroupMap (an updated copy of rsGroupMap)
        this.holder = new RSGroupInfoHolder(newGroupMap);
        LOG.debug("New RSGroup map: {}", newGroupMap);
        // Do not need to update tableMap
        // because only the update on servers in default group is allowed above,
        // or IOException will be thrown
        return;
    }
    /* For online mode, persist to hbase:rsgroup and Zookeeper */
    LOG.debug("Online mode, persisting to {} and ZK", RSGROUP_TABLE_NAME);
    flushConfigTable(newGroupMap);
    // Make changes visible after having been persisted to the source of truth
    resetRSGroupMap(newGroupMap);
    saveRSGroupMapToZK(newGroupMap);
    updateCacheOfRSGroups(newGroupMap.keySet());
    LOG.info("Flush config done, new RSGroup map: {}", newGroupMap);
}
-----------------------
private synchronized void flushConfig(Map<String, RSGroupInfo> newGroupMap) throws IOException {
    // For offline mode persistence is still unavailable
    // We're refreshing in-memory state but only for servers in default group
    if (!isOnline()) {
        if (newGroupMap == holder.groupName2Group) {
            // When newGroupMap is this.rsGroupMap itself,
            // do not need to check default group and other groups as followed
            return;
        }
        LOG.debug("Offline mode, cannot persist to {}", RSGROUP_TABLE_NAME);
        Map<String, RSGroupInfo> oldGroupMap = Maps.newHashMap(holder.groupName2Group);
        RSGroupInfo oldDefaultGroup = oldGroupMap.remove(RSGroupInfo.DEFAULT_GROUP);
        RSGroupInfo newDefaultGroup = newGroupMap.remove(RSGroupInfo.DEFAULT_GROUP);
        if (!oldGroupMap.equals(newGroupMap) || /* compare both tables and servers in other groups */
        !oldDefaultGroup.getTables().equals(newDefaultGroup.getTables())) /* compare tables in default group */
        {
            throw new IOException("Only servers in default group can be updated during offline mode");
        }
        // Restore newGroupMap by putting its default group back
        newGroupMap.put(RSGroupInfo.DEFAULT_GROUP, newDefaultGroup);
        // Refresh rsGroupMap
        // according to the inputted newGroupMap (an updated copy of rsGroupMap)
        this.holder = new RSGroupInfoHolder(newGroupMap);
        LOG.debug("New RSGroup map: {}", newGroupMap);
        // Do not need to update tableMap
        // because only the update on servers in default group is allowed above,
        // or IOException will be thrown
        return;
    }
    /* For online mode, persist to hbase:rsgroup and Zookeeper */
    LOG.debug("Online mode, persisting to {} and ZK", RSGROUP_TABLE_NAME);
    flushConfigTable(newGroupMap);
    // Make changes visible after having been persisted to the source of truth
    resetRSGroupMap(newGroupMap);
    saveRSGroupMapToZK(newGroupMap);
    updateCacheOfRSGroups(newGroupMap.keySet());
    LOG.info("Flush config done, new RSGroup map: {}", newGroupMap);
    {
        List<Mutation> mutations = Lists.newArrayList();
        // populate deletes
        for (String groupName : prevRSGroups) {
            if (!groupMap.containsKey(groupName)) {
                Delete d = new Delete(Bytes.toBytes(groupName));
                mutations.add(d);
            }
        }
        // populate puts
        for (RSGroupInfo gi : groupMap.values()) {
            if (!gi.getName().equals(RSGroupInfo.DEFAULT_GROUP)) {
                RSGroupProtos.RSGroupInfo proto = ProtobufUtil.toProtoGroupInfo(gi);
                Put p = new Put(Bytes.toBytes(gi.getName()));
                p.addColumn(META_FAMILY_BYTES, META_QUALIFIER_BYTES, proto.toByteArray());
                mutations.add(p);
            }
        }
        if (mutations.size() > 0) {
            multiMutate(mutations);
            {
                MutateRowsRequest.Builder builder = MutateRowsRequest.newBuilder();
                for (Mutation mutation : mutations) {
                    if (mutation instanceof Put) {
                        builder.addMutationRequest(ProtobufUtil.toMutation(MutationProto.MutationType.PUT, mutation));
                    } else if (mutation instanceof Delete) {
                        builder.addMutationRequest(ProtobufUtil.toMutation(MutationProto.MutationType.DELETE, mutation));
                    } else {
                        throw new DoNotRetryIOException("multiMutate doesn't support " + mutation.getClass().getName());
                    }
                }
                MutateRowsRequest request = builder.build();
                AsyncTable<?> table = conn.getTable(RSGROUP_TABLE_NAME);
                LOG.debug("Multimutating {} with {} mutations", RSGROUP_TABLE_NAME, mutations.size());
                FutureUtils.get(table.<MultiRowMutationService, MutateRowsResponse>coprocessorService(MultiRowMutationService::newStub, (stub, controller, done) -> stub.mutateRows(controller, request, done), ROW_KEY));
                LOG.info("Multimutating {} with {} mutations done", RSGROUP_TABLE_NAME, mutations.size());
            }
            {
                MutateRowsRequest.Builder builder = MutateRowsRequest.newBuilder();
                for (Mutation mutation : mutations) {
                    if (mutation instanceof Put) {
                        builder.addMutationRequest(ProtobufUtil.toMutation(MutationProto.MutationType.PUT, mutation));
                    } else if (mutation instanceof Delete) {
                        builder.addMutationRequest(ProtobufUtil.toMutation(MutationProto.MutationType.DELETE, mutation));
                    } else {
                        throw new DoNotRetryIOException("multiMutate doesn't support " + mutation.getClass().getName());
                    }
                }
                MutateRowsRequest request = builder.build();
                AsyncTable<?> table = conn.getTable(RSGROUP_TABLE_NAME);
                LOG.debug("Multimutating {} with {} mutations", RSGROUP_TABLE_NAME, mutations.size());
                FutureUtils.get(table.<MultiRowMutationService, MutateRowsResponse>coprocessorService(MultiRowMutationService::newStub, (stub, controller, done) -> stub.mutateRows(controller, request, done), ROW_KEY));
                LOG.info("Multimutating {} with {} mutations done", RSGROUP_TABLE_NAME, mutations.size());
            }
        }
    }
    {
        this.holder = new RSGroupInfoHolder(newRSGroupMap);
    }
    {
        LOG.debug("Saving RSGroup info to ZK");
        try {
            String groupBasePath = ZNodePaths.joinZNode(watcher.getZNodePaths().baseZNode, RS_GROUP_ZNODE);
            ZKUtil.createAndFailSilent(watcher, groupBasePath, ProtobufMagic.PB_MAGIC);
            List<ZKUtil.ZKUtilOp> zkOps = new ArrayList<>(newGroupMap.size());
            for (String groupName : prevRSGroups) {
                if (!newGroupMap.containsKey(groupName)) {
                    String znode = ZNodePaths.joinZNode(groupBasePath, groupName);
                    zkOps.add(ZKUtil.ZKUtilOp.deleteNodeFailSilent(znode));
                }
            }
            for (RSGroupInfo gi : newGroupMap.values()) {
                if (!gi.getName().equals(RSGroupInfo.DEFAULT_GROUP)) {
                    String znode = ZNodePaths.joinZNode(groupBasePath, gi.getName());
                    RSGroupProtos.RSGroupInfo proto = ProtobufUtil.toProtoGroupInfo(gi);
                    LOG.debug("Updating znode: " + znode);
                    ZKUtil.createAndFailSilent(watcher, znode);
                    zkOps.add(ZKUtil.ZKUtilOp.deleteNodeFailSilent(znode));
                    zkOps.add(ZKUtil.ZKUtilOp.createAndFailSilent(znode, ProtobufUtil.prependPBMagic(proto.toByteArray())));
                }
            }
            LOG.debug("Writing ZK GroupInfo count: " + zkOps.size());
            ZKUtil.multiOrSequential(watcher, zkOps, false);
        } catch (KeeperException e) {
            LOG.error("Failed to write to rsGroupZNode", e);
            masterServices.abort("Failed to write to rsGroupZNode", e);
            throw new IOException("Failed to write to rsGroupZNode", e);
        }
    }
}-----------------------
possible Hot2
possible type Hot3_2
1
